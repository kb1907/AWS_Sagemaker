## **AWS Sagemaker Projects**

![](https://miro.medium.com/max/600/0*O3gm8pKaPqgKb-oM.png)



- In this folder, different scale Machine Learning / Deep Learning / NLP projects by using AWS Sagemaker can be found.
- All the projects were done by using real life data.
- This folder will be updated constantly.
- All the best ðŸ¤˜

### AWS Sagemaker Projects

1. [AWS Sagemaker - Object Detection](https://github.com/kb1907/AWS_Sagemaker/blob/main/AWS_Sagemaker_Object_Detection/Sagemaker%20Object%20Detection%20-%20Learner%20Notebook.ipynb)



- In this project I used AWS - Sagemaker for the object detection job. 

2. [AWS Sagemaker - House Prediction](https://github.com/kb1907/AWS_Sagemaker/blob/main/AWS_Sagemaker_House_Prediction/AWSSagemaker_House_Prediction.ipynb)

- In this project, I used classical house prediction data to show two different usage of AWS- Sagemaker (with Python SDK & with Boto3)

3. [BOTO3](https://github.com/kb1907/AWS_Sagemaker/blob/main/AWS_boto3/boto3_read_S3.ipynb)

- In this project I made a gentle intro to Boto3 library.

![](https://cdn-images-1.medium.com/fit/t/700/400/1*DwPGGD3TmeBpxklRGsdfMA.png)

---------------------------------------
## Projects From [Practical Data Science Specialization](https://github.com/kb1907/Practical-Data-Science-Specialization/blob/main/README.md)
------------------------------------------

4. [**AWS Data Wrangler** - Register and Visualize Dataset](https://github.com/kb1907/Practical-Data-Science-Specialization/blob/main/Analyze%20Datasets%20AutoML/Week1/C1_W1_Assignment_Learner.ipynb)

- In this project I ingested and transformed the customer product reviews dataset. 
- Then I used AWS data stack services such as AWS Glue and Amazon Athena for ingesting and querying the dataset. 
- Finally I used AWS Data Wrangler to analyze the dataset and plot some visuals extracting insights.

5. [Detect Data Bias with **Amazon SageMaker Clarify**](https://github.com/kb1907/Practical-Data-Science-Specialization/blob/main/Analyze%20Datasets%20AutoML/Week2/C1_W2_Assignment_Detect_data_bias_with_Amazon_SageMaker_Clarify.ipynb)

- Bias can be present in data before any model training occurs. 
- Inspecting the dataset for bias can help detect collection gaps, inform our feature engineering, and understand societal biases the dataset may reflect. 
- In this project I analyzed bias on the dataset, generated and analyzed bias report, and prepared the dataset for the model training.

6. [Train a BERT Model with **Amazon SageMaker Autopilot**](https://github.com/kb1907/Practical-Data-Science-Specialization/blob/main/Analyze%20Datasets%20AutoML/Week3/C1_W3_Assignment.ipynb)

- In this project, I used Amazon Sagemaker Autopilot to train a BERT-based natural language processing (NLP) model. 
- The model analyzed customer feedback and classified the messages into positive (1), neutral (0) and negative (-1) sentiment.

7. [Train a Text Classifier using **Amazon SageMaker BlazingText** built-in algorithm](https://github.com/kb1907/Practical-Data-Science-Specialization/blob/main/Analyze%20Datasets%20AutoML/Week4/C1_W4_Assignment.ipynb)

- In this project, I used SageMaker BlazingText built-in algorithm to predict the sentiment for each customer review. 
- BlazingText is a variant of FastText which is based on word2vec. 

8. [Feature transformation with Amazon SageMaker processing job and Feature Store](https://github.com/kb1907/Practical-Data-Science-Specialization/blob/main/Build%20Train%20and%20Deploy%20ML%20Pipelines%20using%20BERT/Week1/C2_W1_Assignment.ipynb)

- In this project I started with the raw Women's Clothing Reviews dataset 
- And prepared it to train a BERT-based natural language processing (NLP) model. 


9. [Train a review classifier with BERT and Amazon SageMaker](https://github.com/kb1907/Practical-Data-Science-Specialization/blob/main/Build%20Train%20and%20Deploy%20ML%20Pipelines%20using%20BERT/Week2/C2_W2_Assignment.ipynb)

- In this project, I trained a text classifier using a variant of BERT called RoBERTa - a Robustly Optimized BERT Pretraining Approach - within a PyTorch model ran as a SageMaker Training Job.

10. [Optimize models using Automatic Model Tuning](https://github.com/kb1907/Practical-Data-Science-Specialization/blob/main/Optimize%20ML%20Models%20and%20Deploy%20Human-in-the-Loop%20Pipelines/Week1/C3_W1_Assignment.ipynb)

-  In this project, I applied a random algorithm of Automated Hyperparameter Tuning to train a BERT-based natural language processing (NLP) classifier. 

11. [A/B testing, traffic shifting and autoscaling](https://github.com/kb1907/Practical-Data-Science-Specialization/blob/main/Optimize%20ML%20Models%20and%20Deploy%20Human-in-the-Loop%20Pipelines/Week2/C3_W2_Assignment.ipynb)

- In this project, I made an endpoint with multiple variants, splitting the traffic between them. 
- Then after testing and reviewing the endpoint performance metrics, I shifted the traffic to one variant and configure it to autoscale.

12. [Data labeling and human-in-the-loop pipelines with Amazon Augmented AI (A2I)](https://github.com/kb1907/Practical-Data-Science-Specialization/blob/main/Optimize%20ML%20Models%20and%20Deploy%20Human-in-the-Loop%20Pipelines/Week3/C3_W3_Assignment.ipynb)

- In this project, I made my own human workforce, a human task UI, and then defined the human review workflow to perform data labeling. 
- I made the original predictions of the labels with the custom ML model, and then made a human loop if the probability scores are lower than the preset threshold. 
- After the completion of the human loop tasks, I reviewed the results and prepare data for re-training.



-------------------------------------------------

[AWS Sagemaker examples - Forked from aws/amazon-sagemaker-examples](https://github.com/kb1907/amazon-sagemaker-examples) 
